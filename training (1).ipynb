{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e308de64",
      "metadata": {
        "id": "e308de64",
        "outputId": "d61be3fc-7d03-404c-bd92-d89d6feb7407"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9710144927536232\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "file_path = r'C:\\Users\\THASNEEM FATHIMA\\Downloads\\smoteagain.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "target_column = \"num\"\n",
        "X = data.drop(columns=[target_column])\n",
        "y = data[target_column]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "et_classifier = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
        "et_classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = et_classifier.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5498a99",
      "metadata": {
        "id": "b5498a99",
        "outputId": "de383e1d-45d2-4b2a-ba9a-4f157cda0126"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9637681159420289\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "file_path = r'C:\\Users\\THASNEEM FATHIMA\\Downloads\\fcbfdata.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "target_column = \"num\"\n",
        "X = data.drop(columns=[target_column])\n",
        "y = data[target_column]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "et_classifier = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
        "et_classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = et_classifier.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "724a44a4",
      "metadata": {
        "id": "724a44a4",
        "outputId": "0bcbfdca-9f1c-4f0e-d4c4-fd1fb27a81d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial parameter: 100\n",
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
            "[CV] END ....................................n_estimators=81; total time=   0.0s\n",
            "[CV] END ....................................n_estimators=81; total time=   0.0s\n",
            "[CV] END ....................................n_estimators=81; total time=   0.0s\n",
            "[CV] END ....................................n_estimators=81; total time=   0.0s\n",
            "[CV] END ....................................n_estimators=81; total time=   0.0s\n",
            "[CV] END ....................................n_estimators=85; total time=   0.0s\n",
            "[CV] END ....................................n_estimators=85; total time=   0.0s\n",
            "[CV] END ....................................n_estimators=85; total time=   0.0s\n",
            "[CV] END ....................................n_estimators=85; total time=   0.0s\n",
            "[CV] END ....................................n_estimators=85; total time=   0.0s\n",
            "[CV] END ....................................n_estimators=90; total time=   0.0s\n",
            "[CV] END ....................................n_estimators=90; total time=   0.0s\n",
            "[CV] END ....................................n_estimators=90; total time=   0.0s\n",
            "[CV] END ....................................n_estimators=90; total time=   0.0s\n",
            "[CV] END ....................................n_estimators=90; total time=   0.0s\n",
            "[CV] END ....................................n_estimators=95; total time=   0.1s\n",
            "[CV] END ....................................n_estimators=95; total time=   0.1s\n",
            "[CV] END ....................................n_estimators=95; total time=   0.1s\n",
            "[CV] END ....................................n_estimators=95; total time=   0.1s\n",
            "[CV] END ....................................n_estimators=95; total time=   0.1s\n",
            "[CV] END ...................................n_estimators=100; total time=   0.1s\n",
            "[CV] END ...................................n_estimators=100; total time=   0.1s\n",
            "[CV] END ...................................n_estimators=100; total time=   0.0s\n",
            "[CV] END ...................................n_estimators=100; total time=   0.0s\n",
            "[CV] END ...................................n_estimators=100; total time=   0.1s\n",
            "Best parameter: {'n_estimators': 81}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(r'C:\\Users\\THASNEEM FATHIMA\\Downloads\\aco2.csv')\n",
        "\n",
        "X = data.drop('num', axis=1)\n",
        "y = data['num']\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [81, 85, 90, 95, 100]\n",
        "}\n",
        "\n",
        "et_classifier = ExtraTreesClassifier(random_state=42)\n",
        "print(\"Initial parameter:\", et_classifier.get_params()['n_estimators'])\n",
        "grid_search = GridSearchCV(estimator=et_classifier, param_grid=param_grid, cv=5, scoring='accuracy', verbose=2)\n",
        "\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "print(\"Best parameter:\", grid_search.best_params_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d8893df7",
      "metadata": {
        "id": "d8893df7",
        "outputId": "b0e5b971-f0ea-4a39-976d-6edcd567b3fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 1.0\n",
            "Training Confusion Matrix:\n",
            "[[102   0   0   0   0]\n",
            " [  0 107   0   0   0]\n",
            " [  0   0 113   0   0]\n",
            " [  0   0   0 113   0]\n",
            " [  0   0   0   0 115]]\n",
            "Training Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       102\n",
            "           1       1.00      1.00      1.00       107\n",
            "           2       1.00      1.00      1.00       113\n",
            "           3       1.00      1.00      1.00       113\n",
            "           4       1.00      1.00      1.00       115\n",
            "\n",
            "    accuracy                           1.00       550\n",
            "   macro avg       1.00      1.00      1.00       550\n",
            "weighted avg       1.00      1.00      1.00       550\n",
            "\n",
            "Testing Accuracy: 0.9855072463768116\n",
            "Testing Confusion Matrix:\n",
            "[[16  0  0  1  0]\n",
            " [ 0 29  1  0  0]\n",
            " [ 0  0 28  0  0]\n",
            " [ 0  0  0 25  0]\n",
            " [ 0  0  0  0 38]]\n",
            "Testing Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.94      0.97        17\n",
            "           1       1.00      0.97      0.98        30\n",
            "           2       0.97      1.00      0.98        28\n",
            "           3       0.96      1.00      0.98        25\n",
            "           4       1.00      1.00      1.00        38\n",
            "\n",
            "    accuracy                           0.99       138\n",
            "   macro avg       0.99      0.98      0.98       138\n",
            "weighted avg       0.99      0.99      0.99       138\n",
            "\n",
            "Training Time: 0.7664880752563477 seconds\n",
            "Memory Usage: 236.0703125 MB\n",
            "Bias: 0.01744186046511628\n",
            "Variance: 1.9556157889399677\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import psutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def memory_usage():\n",
        "    process = psutil.Process()\n",
        "    return process.memory_info().rss / 1024 ** 2\n",
        "data = pd.read_csv('/content/sample_data/aco2.csv')\n",
        "X = data.drop('num', axis=1).astype(np.float32)\n",
        "y = data['num']\n",
        "X = csr_matrix(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "clf = ExtraTreesClassifier(n_estimators=80,max_depth=17, max_features=3, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "training_time = time.time() - start_time\n",
        "training_time = time.time() - start_time\n",
        "y_pred_train = clf.predict(X_train)\n",
        "cm = confusion_matrix(y_train, y_pred_train)\n",
        "\n",
        "cr = classification_report(y_train, y_pred_train)\n",
        "training_acc = accuracy_score(y_train, y_pred_train)\n",
        "print(\"Training Accuracy:\", training_acc)\n",
        "print(\"Training Confusion Matrix:\")\n",
        "print(cm)\n",
        "print(\"Training Classification Report:\")\n",
        "print(cr)\n",
        "y_pred_test = clf.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred_test)\n",
        "cr = classification_report(y_test, y_pred_test)\n",
        "testing_acc = accuracy_score(y_test, y_pred_test)\n",
        "print(\"Testing Accuracy:\", testing_acc)\n",
        "print(\"Testing Confusion Matrix:\")\n",
        "print(cm)\n",
        "print(\"Testing Classification Report:\")\n",
        "print(cr)\n",
        "print(\"Training Time:\", training_time, \"seconds\")\n",
        "print(\"Memory Usage:\", memory_usage(), \"MB\")\n",
        "predicted = cross_val_predict(clf, X, y, cv=5)\n",
        "bias = np.mean(predicted - y)\n",
        "variance = np.var(predicted)\n",
        "print(\"Bias:\", bias)\n",
        "print(\"Variance:\", variance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "08215385",
      "metadata": {
        "id": "08215385",
        "outputId": "bce4b933-9523-48e5-b5a1-8605ffc0f66a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 1.0\n",
            "Training Confusion Matrix:\n",
            "[[102   0   0   0   0]\n",
            " [  0 107   0   0   0]\n",
            " [  0   0 113   0   0]\n",
            " [  0   0   0 113   0]\n",
            " [  0   0   0   0 115]]\n",
            "Training Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       102\n",
            "           1       1.00      1.00      1.00       107\n",
            "           2       1.00      1.00      1.00       113\n",
            "           3       1.00      1.00      1.00       113\n",
            "           4       1.00      1.00      1.00       115\n",
            "\n",
            "    accuracy                           1.00       550\n",
            "   macro avg       1.00      1.00      1.00       550\n",
            "weighted avg       1.00      1.00      1.00       550\n",
            "\n",
            "Testing Accuracy: 0.9347826086956522\n",
            "Testing Confusion Matrix:\n",
            "[[16  0  0  1  0]\n",
            " [ 2 24  1  2  1]\n",
            " [ 0  0 27  1  0]\n",
            " [ 0  1  0 24  0]\n",
            " [ 0  0  0  0 38]]\n",
            "Testing Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.94      0.91        17\n",
            "           1       0.96      0.80      0.87        30\n",
            "           2       0.96      0.96      0.96        28\n",
            "           3       0.86      0.96      0.91        25\n",
            "           4       0.97      1.00      0.99        38\n",
            "\n",
            "    accuracy                           0.93       138\n",
            "   macro avg       0.93      0.93      0.93       138\n",
            "weighted avg       0.94      0.93      0.93       138\n",
            "\n",
            "Training Time: 0.22043752670288086 seconds\n",
            "Memory Usage: 231.609375 MB\n",
            "Bias: 0.011627906976744186\n",
            "Variance: 1.9918346910492162\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import psutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def memory_usage():\n",
        "    process = psutil.Process()\n",
        "    return process.memory_info().rss / 1024 ** 2\n",
        "data = pd.read_csv('/content/sample_data/acorf.csv')\n",
        "X = data.drop('num', axis=1).astype(np.float32)\n",
        "y = data['num']\n",
        "X = csr_matrix(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=81, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "training_time = time.time() - start_time\n",
        "y_pred_train = clf.predict(X_train)\n",
        "cm = confusion_matrix(y_train, y_pred_train)\n",
        "\n",
        "cr = classification_report(y_train, y_pred_train)\n",
        "training_acc = accuracy_score(y_train, y_pred_train)\n",
        "print(\"Training Accuracy:\", training_acc)\n",
        "print(\"Training Confusion Matrix:\")\n",
        "print(cm)\n",
        "print(\"Training Classification Report:\")\n",
        "print(cr)\n",
        "y_pred_test = clf.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred_test)\n",
        "cr = classification_report(y_test, y_pred_test)\n",
        "testing_acc = accuracy_score(y_test, y_pred_test)\n",
        "print(\"Testing Accuracy:\", testing_acc)\n",
        "print(\"Testing Confusion Matrix:\")\n",
        "print(cm)\n",
        "print(\"Testing Classification Report:\")\n",
        "print(cr)\n",
        "print(\"Training Time:\", training_time, \"seconds\")\n",
        "print(\"Memory Usage:\", memory_usage(), \"MB\")\n",
        "predicted = cross_val_predict(clf, X, y, cv=5)\n",
        "bias = np.mean(predicted - y)\n",
        "variance = np.var(predicted)\n",
        "print(\"Bias:\", bias)\n",
        "print(\"Variance:\", variance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "03c2b54f",
      "metadata": {
        "id": "03c2b54f",
        "outputId": "1a28333e-961e-421b-8d79-e51912bc71cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 1.0\n",
            "Training Confusion Matrix:\n",
            "[[102   0   0   0   0]\n",
            " [  0 107   0   0   0]\n",
            " [  0   0 113   0   0]\n",
            " [  0   0   0 113   0]\n",
            " [  0   0   0   0 115]]\n",
            "Training Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       102\n",
            "           1       1.00      1.00      1.00       107\n",
            "           2       1.00      1.00      1.00       113\n",
            "           3       1.00      1.00      1.00       113\n",
            "           4       1.00      1.00      1.00       115\n",
            "\n",
            "    accuracy                           1.00       550\n",
            "   macro avg       1.00      1.00      1.00       550\n",
            "weighted avg       1.00      1.00      1.00       550\n",
            "\n",
            "Testing Accuracy: 0.9057971014492754\n",
            "Testing Confusion Matrix:\n",
            "[[16  1  0  0  0]\n",
            " [ 3 23  2  2  0]\n",
            " [ 0  3 24  1  0]\n",
            " [ 0  1  0 24  0]\n",
            " [ 0  0  0  0 38]]\n",
            "Testing Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.94      0.89        17\n",
            "           1       0.82      0.77      0.79        30\n",
            "           2       0.92      0.86      0.89        28\n",
            "           3       0.89      0.96      0.92        25\n",
            "           4       1.00      1.00      1.00        38\n",
            "\n",
            "    accuracy                           0.91       138\n",
            "   macro avg       0.90      0.90      0.90       138\n",
            "weighted avg       0.91      0.91      0.90       138\n",
            "\n",
            "Training Time: 6.740320205688477 seconds\n",
            "Memory Usage: 218.32421875 MB\n",
            "Bias: -0.036337209302325583\n",
            "Variance: 1.9813750676041102\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import psutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def memory_usage():\n",
        "    process = psutil.Process()\n",
        "    return process.memory_info().rss / 1024 ** 2\n",
        "data = pd.read_csv('/content/sample_data/acoxg.csv')\n",
        "X = data.drop('num', axis=1).astype(np.float32)\n",
        "y = data['num']\n",
        "X = csr_matrix(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "model = xgb.XGBClassifier(objective='multi:softmax', num_class=5)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "training_time = time.time() - start_time\n",
        "y_pred_train = model.predict(X_train)\n",
        "cm = confusion_matrix(y_train, y_pred_train)\n",
        "\n",
        "cr = classification_report(y_train, y_pred_train)\n",
        "training_acc = accuracy_score(y_train, y_pred_train)\n",
        "print(\"Training Accuracy:\", training_acc)\n",
        "print(\"Training Confusion Matrix:\")\n",
        "print(cm)\n",
        "print(\"Training Classification Report:\")\n",
        "print(cr)\n",
        "y_pred_test = model.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred_test)\n",
        "cr = classification_report(y_test, y_pred_test)\n",
        "testing_acc = accuracy_score(y_test, y_pred_test)\n",
        "print(\"Testing Accuracy:\", testing_acc)\n",
        "print(\"Testing Confusion Matrix:\")\n",
        "print(cm)\n",
        "print(\"Testing Classification Report:\")\n",
        "print(cr)\n",
        "print(\"Training Time:\", training_time, \"seconds\")\n",
        "print(\"Memory Usage:\", memory_usage(), \"MB\")\n",
        "predicted = cross_val_predict(model, X, y, cv=5)\n",
        "bias = np.mean(predicted - y)\n",
        "variance = np.var(predicted)\n",
        "print(\"Bias:\", bias)\n",
        "print(\"Variance:\", variance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ccef5120",
      "metadata": {
        "id": "ccef5120"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # Data\n",
        "# deployment = ['Edge', 'Cloud']\n",
        "# latency = [0.001358, 0.012269]\n",
        "\n",
        "# # Plotting\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# plt.bar(deployment, latency, color=['blue', 'orange'])\n",
        "\n",
        "# # Adding labels and title\n",
        "# plt.xlabel('Deployment')\n",
        "# plt.ylabel('Latency (s)')\n",
        "# plt.title('Comparison of Deployment Latency')\n",
        "# plt.ylim(0, max(latency) * 1.1)\n",
        "\n",
        "# # Display the plot\n",
        "# plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}